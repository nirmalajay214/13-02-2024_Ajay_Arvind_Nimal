{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QSHb_vw3NdBs"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and preprocess the data\n",
        "historic_data = pd.read_csv(\"historic.csv\")\n",
        "prediction_data = pd.read_csv(\"prediction_input.csv\")\n",
        "\n",
        "# Fill missing values\n",
        "historic_data.fillna(method='ffill', inplace=True)\n",
        "prediction_data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "historic_data = pd.get_dummies(historic_data, columns=['category', 'main_promotion', 'color'])\n",
        "prediction_data = pd.get_dummies(prediction_data, columns=['category', 'main_promotion', 'color'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "historic_data_scaled = scaler.fit_transform(historic_data.drop(columns=['success_indicator', 'item_no']))\n",
        "prediction_data_scaled = scaler.transform(prediction_data.drop(columns=['item_no']))\n",
        "\n",
        "# Convert categorical labels to binary\n",
        "historic_data['success_indicator'] = historic_data['success_indicator'].map({'flop': 0, 'top': 1})\n",
        "\n",
        "# Split training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(historic_data_scaled, historic_data['success_indicator'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "_EyB7dXNNsHi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define functions/classes for different models\n",
        "\n",
        "class LogisticRegressionModel:\n",
        "    def __init__(self):\n",
        "        self.model = LogisticRegression()\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        y_pred = self.model.predict(X)\n",
        "        return classification_report(y, y_pred), accuracy_score(y, y_pred)\n",
        "\n",
        "class ANNModel:\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.3),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.model.fit(X, y, epochs=20, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        loss, accuracy = self.model.evaluate(X, y)\n",
        "        return classification_report(y, (self.model.predict(X) > 0.5).astype(\"int32\")), accuracy\n"
      ],
      "metadata": {
        "id": "OTfmSGiAOHE7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train and evaluate each model\n",
        "logistic_regression_model = LogisticRegressionModel()\n",
        "logistic_regression_model.train(X_train, y_train)\n",
        "logistic_regression_report, logistic_regression_accuracy = logistic_regression_model.evaluate(X_test, y_test)\n",
        "\n",
        "ann_model = ANNModel()\n",
        "ann_model.train(X_train, y_train)\n",
        "ann_report, ann_accuracy = ann_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNKOLyR-OKtb",
        "outputId": "73826e50-cb32-47cc-ce96-96467c77d0fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "80/80 [==============================] - 2s 5ms/step - loss: 0.5877 - accuracy: 0.6898 - val_loss: 0.4695 - val_accuracy: 0.8172\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7896 - val_loss: 0.4375 - val_accuracy: 0.8445\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8141 - val_loss: 0.4236 - val_accuracy: 0.8453\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8213 - val_loss: 0.4198 - val_accuracy: 0.8445\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8279 - val_loss: 0.4146 - val_accuracy: 0.8477\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8338 - val_loss: 0.4125 - val_accuracy: 0.8477\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8365 - val_loss: 0.4135 - val_accuracy: 0.8453\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8383 - val_loss: 0.4121 - val_accuracy: 0.8492\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8410 - val_loss: 0.4076 - val_accuracy: 0.8508\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8404 - val_loss: 0.4075 - val_accuracy: 0.8523\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8404 - val_loss: 0.4073 - val_accuracy: 0.8516\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8414 - val_loss: 0.4043 - val_accuracy: 0.8500\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8420 - val_loss: 0.4021 - val_accuracy: 0.8484\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8494 - val_loss: 0.4018 - val_accuracy: 0.8500\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8441 - val_loss: 0.4048 - val_accuracy: 0.8484\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8492 - val_loss: 0.4027 - val_accuracy: 0.8484\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8527 - val_loss: 0.4009 - val_accuracy: 0.8508\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8475 - val_loss: 0.3995 - val_accuracy: 0.8531\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8500 - val_loss: 0.4020 - val_accuracy: 0.8492\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8555 - val_loss: 0.4017 - val_accuracy: 0.8516\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8487\n",
            "50/50 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compare the performance of the models\n",
        "print(\"Logistic Regression Model Evaluation:\")\n",
        "print(logistic_regression_report)\n",
        "print(\"Logistic Regression Model Accuracy:\", logistic_regression_accuracy)\n",
        "\n",
        "print(\"\\nANN Model Evaluation:\")\n",
        "print(ann_report)\n",
        "print(\"ANN Model Accuracy:\", ann_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZgG0N9YOPx0",
        "outputId": "1d52e041-7ac5-496c-b981-445b6d106137"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.66      0.72       571\n",
            "           1       0.83      0.91      0.87      1029\n",
            "\n",
            "    accuracy                           0.82      1600\n",
            "   macro avg       0.81      0.78      0.79      1600\n",
            "weighted avg       0.82      0.82      0.81      1600\n",
            "\n",
            "Logistic Regression Model Accuracy: 0.818125\n",
            "\n",
            "ANN Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       571\n",
            "           1       0.85      0.93      0.89      1029\n",
            "\n",
            "    accuracy                           0.85      1600\n",
            "   macro avg       0.85      0.82      0.83      1600\n",
            "weighted avg       0.85      0.85      0.84      1600\n",
            "\n",
            "ANN Model Accuracy: 0.8487499952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Choose the best-performing model and provide a summary\n",
        "if logistic_regression_accuracy > ann_accuracy:\n",
        "    print(\"\\nBest Model: Logistic Regression\")\n",
        "    print(\"Reason for Choosing: Logistic Regression has a higher accuracy compared to the ANN model.\")\n",
        "else:\n",
        "    print(\"\\nBest Model: ANN\")\n",
        "    print(\"Reason for Choosing: ANN has a higher accuracy compared to the Logistic Regression model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eadlQwdwOSG0",
        "outputId": "38a96cab-bf44-4dfb-e776-2778a33c1869"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model: ANN\n",
            "Reason for Choosing: ANN has a higher accuracy compared to the Logistic Regression model.\n"
          ]
        }
      ]
    }
  ]
}